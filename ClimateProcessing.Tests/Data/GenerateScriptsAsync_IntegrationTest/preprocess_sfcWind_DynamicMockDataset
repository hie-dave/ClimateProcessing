#!/usr/bin/env bash
#PBS -N preprocess_sfcWind_DynamicMockDataset
#PBS -o @#OUTPUT_DIRECTORY#@/logs/preprocess_sfcWind_DynamicMockDataset.log
#PBS -P test
#PBS -q megamem
#PBS -l walltime=06:30:00
#PBS -l ncpus=1
#PBS -l mem=64GB
#PBS -l jobfs=128GB
#PBS -j oe
#PBS -M test@example.com
#PBS -m abe

# This script was automatically generated. Do not modify.

# Exit immediately if any command fails.
set -euo pipefail

# Load required modules.
module purge
module load pbs netcdf cdo nco python3/3.12.1

# Create temporary directory and cd into it.
WORK_DIR="$(mktemp -d -p "${PBS_JOBFS}")"
cd "${WORK_DIR}"

# Delete the temporary directory on exit.
trap 'cd "${PBS_JOBFS}"; rm -rf "${WORK_DIR}"' EXIT

# Stream all output to a log file without buffering.
STREAM_FILE="@#OUTPUT_DIRECTORY#@/streams/preprocess_sfcWind_DynamicMockDataset.log"
rm -f "${STREAM_FILE}"
exec 1> >(tee -a "${STREAM_FILE}") 2>&1

# Print a log message.
log() {
    echo "[$(date)] $*"
}

# File paths.
IN_DIR="/input/WindSpeed"
OUT_DIR="@#OUTPUT_DIRECTORY#@/tmp/dynamic_mock/sfcWind"
GRID_FILE="/home/giraffe/grid.nc"
COMMANDS_FILE="${WORK_DIR}/commands.txt"

mkdir -p "${OUT_DIR}"

# Perform corrective operations on input files:
# - Remap input files to target grid.
# - Unpack data.
# - Aggregate data from 1hour to 3hour.
# Generate commands file.
for FILE in "${IN_DIR}"/*.nc
do
    echo cdo -L -O -v -z zip1 -timselmean,3 -unpack -remapbil,"${GRID_FILE}" "${FILE}" "${OUT_DIR}/$(basename "${FILE}")" >> "${COMMANDS_FILE}"
done

# Load additional modules required for parallel processing.
module load openmpi nci-parallel

 # Pre-process files in parallel.
mpirun -n 2 nci-parallel --input-file "${COMMANDS_FILE}"
